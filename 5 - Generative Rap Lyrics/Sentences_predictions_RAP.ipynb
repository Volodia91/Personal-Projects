{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentences_predictions_RAP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FsmAf5UOgDh-",
        "JJ1gonZrgVU9",
        "-HMHXUuoiTIe",
        "331hA3-gUuTe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsmAf5UOgDh-",
        "colab_type": "text"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ1gonZrgVU9",
        "colab_type": "text"
      },
      "source": [
        "##Import des librairies et des textes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pin3GAsflQ4",
        "colab_type": "code",
        "outputId": "cee21357-b303-48ad-d517-11d067e1b190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fndGHVJ9hKfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nekfeu = pd.read_csv(\"nekfeu.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HMHXUuoiTIe",
        "colab_type": "text"
      },
      "source": [
        "##Traitement du texte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9flU_bFf02H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_lines(lyrics):\n",
        "  lyrics.lyrics = lyrics.lyrics.apply(lambda x: str(x))\n",
        "  liste = []\n",
        "  for i in range(len(lyrics)):\n",
        "    lyric = lyrics.lyrics[i].splitlines()\n",
        "    liste+=lyric\n",
        "  dataset = pd.DataFrame(liste, columns=['sentences'])\n",
        "  return(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g00wQaRh0-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = split_lines(nekfeu)\n",
        "initial_len = len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relxHwjkPC-l",
        "colab_type": "code",
        "outputId": "dbb793d1-65c3-4923-c1dd-6a77f46e1685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Nous avons {} lignes initialement'.format(initial_len))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nous avons 8133 lignes initialement\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63fw5eXyD8Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drop_null_sentence(dataset):\n",
        "  drop = list()\n",
        "  for i in range(len(dataset.sentences)):\n",
        "    if len(dataset.sentences[i].split(' '))<2:\n",
        "      drop.append(i)\n",
        "  dataset = dataset.drop(index=drop)\n",
        "  dataset = dataset.reset_index()\n",
        "  return(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Upis0x7SAH",
        "colab_type": "code",
        "outputId": "947426ca-5b25-44f8-db9c-f64118fde3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = drop_null_sentence(dataset)\n",
        "print('Il nous reste {} lignes ({}%)'.format(len(dataset),round(len(dataset)/initial_len*100,1)))\n",
        "data = dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il nous reste 7480 lignes (92.0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34zW4PXmch4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputdict = {'?':'', '...':'', '!':'', '(':'', ')':'','\"':'', \"'\":'', '/':'', '.':' ', ',':'', ':':''}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cn9PcP9WDkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Suppression de la ponctuation et des caractÃ¨res de l'inputdict\n",
        "def text_harmonization(dataset):\n",
        "  sentences = dataset.sentences.apply(lambda x: x.lower())\n",
        "  s=' '\n",
        "  phrase_clean = []\n",
        "  for sentence in sentences:\n",
        "    for word, initial in inputdict.items():\n",
        "      sentence = sentence.replace(word.lower(), initial)\n",
        "    phrase_clean.append(sentence)\n",
        "  dataset_harmonized = pd.DataFrame(phrase_clean, columns=[\"sentences\"])\n",
        "  return(dataset_harmonized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tefi3TwEcdCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = text_harmonization(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an-5ox8-xEES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python program to check if two to get unique values from list\n",
        "# using traversal function to get unique values\n",
        "\n",
        "def unique(liste):\n",
        "    # intilize a null list\n",
        "    unique_list = []\n",
        "    # traverse for all elements\n",
        "    for x in liste:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return(unique_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EocdL4jqAG5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def del_word_repeat(dataset):\n",
        "  space = ' '\n",
        "  data = []\n",
        "  for sentence in dataset.sentences:\n",
        "    word = sentence.split()\n",
        "    if len(word)>0:  \n",
        "      new_sentence = [word[0]]\n",
        "    for i in range(1,len(word)):\n",
        "      if word[i-1]!=word[i]:\n",
        "        new_sentence.append(word[i])\n",
        "    new_sentence = space.join(new_sentence)\n",
        "    data.append((new_sentence))\n",
        "    dataset = pd.DataFrame(data, columns=['sentences'])\n",
        "  return(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVXUK6hZ3R2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = del_word_repeat(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3dEO1ENxp4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def del_repeat(dataset):\n",
        "  sentences = dataset.sentences\n",
        "  clean = []\n",
        "  for phrase in sentences:\n",
        "    split = phrase.split(' ')\n",
        "    if len(unique(split)) > len(split)/2:\n",
        "      clean.append(split)\n",
        "  for i in range(len(clean)):\n",
        "    s = ' '\n",
        "    clean[i] = s.join(clean[i])\n",
        "  return(pd.DataFrame(clean, columns=['sentences']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv4j-il8zcWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = del_repeat(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKZlRnUDe3xA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def del_sentences_repeat(dataset):\n",
        "  sentences = dataset.sentences\n",
        "  clean = []\n",
        "  for i in range(len(sentences)-2):\n",
        "    if sentences[i]!=sentences[i+1] and sentences[i]!=sentences[i+2]:\n",
        "      clean.append(sentences[i])\n",
        "  dataset = pd.DataFrame(clean, columns=['sentences'])\n",
        "  return(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHdR7D3DmhVF",
        "colab_type": "code",
        "outputId": "06132c91-bf4f-435c-c770-5f1a98b2bd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = del_sentences_repeat(dataset)\n",
        "print('Il nous reste {} lignes ({}%)'.format(len(dataset),round(len(dataset)/initial_len*100,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il nous reste 7077 lignes (87.0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "331hA3-gUuTe",
        "colab_type": "text"
      },
      "source": [
        "#Export des dataset_clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltyYeFzNVExu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "booba = pd.read_csv(\"booba.csv\")\n",
        "damso = pd.read_csv(\"damso.csv\")\n",
        "guizmo = pd.read_csv(\"guizmo.csv\")\n",
        "kaaris = pd.read_csv(\"kaaris.csv\")\n",
        "lomepal = pd.read_csv(\"lomepal.csv\")\n",
        "nekfeu = pd.read_csv(\"nekfeu.csv\")\n",
        "nepal = pd.read_csv(\"nepal.csv\")\n",
        "orelsan = pd.read_csv(\"orelsan.csv\")\n",
        "pnl = pd.read_csv(\"pnl.csv\")\n",
        "sch = pd.read_csv(\"sch.csv\")\n",
        "vald = pd.read_csv(\"vald.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5B1lJWVY6E",
        "colab_type": "code",
        "outputId": "033188d0-92a4-4b13-bea0-a85814ae75ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rap_lyrics = [booba, damso, guizmo, kaaris, lomepal, nekfeu, nepal, orelsan, pnl, sch, vald]\n",
        "rap_names = ['booba', 'damso', 'guizmo', 'kaaris', 'lomepal', 'nekfeu', 'nepal', 'orelsan', 'pnl', 'sch', 'vald']\n",
        "\n",
        "for lyric in range(len(rap_lyrics)):\n",
        "  dt = split_lines(rap_lyrics[lyric])\n",
        "  initial_len = len(dt)\n",
        "  dt = drop_null_sentence(dt)\n",
        "  dt = drop_null_sentence(text_harmonization(dt))\n",
        "  dt = drop_null_sentence(del_word_repeat(dt))\n",
        "  dt = del_sentences_repeat(dt)\n",
        "  dt = del_repeat(dt)\n",
        "  csv = rap_names[lyric]+'_clean.csv'\n",
        "  dt.to_csv(csv, index = False, header=True)\n",
        "  print(rap_names[lyric] + ' -> Il nous reste {} lignes ({}%)'.format(len(dt),round(len(dt)/initial_len*100,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "booba -> Il nous reste 10435 lignes (85.2%)\n",
            "damso -> Il nous reste 4260 lignes (81.3%)\n",
            "guizmo -> Il nous reste 11910 lignes (87.8%)\n",
            "kaaris -> Il nous reste 7856 lignes (78.2%)\n",
            "lomepal -> Il nous reste 4113 lignes (85.2%)\n",
            "nekfeu -> Il nous reste 7019 lignes (86.3%)\n",
            "nepal -> Il nous reste 1988 lignes (84.3%)\n",
            "orelsan -> Il nous reste 4614 lignes (86.0%)\n",
            "pnl -> Il nous reste 3975 lignes (82.7%)\n",
            "sch -> Il nous reste 5656 lignes (86.3%)\n",
            "vald -> Il nous reste 8710 lignes (83.3%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyd0Wr07U061",
        "colab_type": "code",
        "outputId": "ea2ccbf3-4f9c-42dd-db0b-780a63ac3140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "b2o = pd.read_csv(\"damso_clean.csv\")\n",
        "b2o.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentences    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBOH_sZRenSV",
        "colab_type": "text"
      },
      "source": [
        "#Transformation d'un texte en syllables IPA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca4aS1WEPFb2",
        "colab_type": "code",
        "outputId": "dfcb5dec-cf26-45ce-d1f4-a074f767d302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip install epitran"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: epitran in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.6/dist-packages (from epitran) (0.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from epitran) (46.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from epitran) (2019.12.20)\n",
            "Requirement already satisfied: panphon>=0.16 in /usr/local/lib/python3.6/dist-packages (from epitran) (0.17)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from epitran) (0.7.5)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (1.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (1.18.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldNnk5AZz0o7",
        "colab_type": "code",
        "outputId": "2a21d3de-c245-49cb-c1ec-e8f208301d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install FinnSyll"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: FinnSyll in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.6/dist-packages (from FinnSyll) (2.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM1IhOepQP57",
        "colab_type": "code",
        "outputId": "37dbe479-a090-46ac-f1f4-1ee9598164ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import epitran\n",
        "import math\n",
        "import numpy as np\n",
        "from finnsyll import FinnSyll\n",
        "import pandas as pd\n",
        "\n",
        "f = FinnSyll()\n",
        "epi = epitran.Epitran('fra-Latn')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:morfessor.io:Loading model from '/usr/local/lib/python3.6/dist-packages/finnsyll/data/finnsyll-morfessor.bin'...\n",
            "INFO:morfessor.io:Done.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9B0o1S2QFld",
        "colab_type": "code",
        "outputId": "2b6c64a5-3b51-4e2d-9711-b34ef56772fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(epi.transliterate('Ce ci est une ri me'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sÉ si Ést ynÉ ri m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1gKgqQukoqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = \"vitamine verte pÃ©dÃ© des fois jmimagine espÃ©rer\"\n",
        "sequence1 = \"vis ta vie jette les dÃ©s mÃªme si les pyramides guettent pÃ©dÃ©\"\n",
        "sequence2 = \"la vie ma fait connaÃ®tre des putains dâbraves avec des tÃªtes de lossbar\"\n",
        "sequence3 = \"mais ces lascars qui font du zgar et mont lance-ba mÃ©ritent loscar\"\n",
        "sequence4 = \"seuls les coups durs officialisent les reufs\"\n",
        "sequence5 = \"quand tes dans le vice la vie cest reuch\"\n",
        "sequence6 = \"il faut quje fasse le point je nsuis pas devin mais si je clamse demain\"\n",
        "sequence7 = \"jveux pas qulimpact dune balle de flingue devienne mon clap de fin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzEVV9Q4lEky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = [sequence, sequence1, sequence2, sequence3, sequence4, sequence5, sequence6, sequence7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNBjts_KyVqh",
        "colab_type": "text"
      },
      "source": [
        "#Transformation des phrases en syllables puis en phonÃ©tique\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcSqNg2-0Ap3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputdict = {'.':' ','â':''}\n",
        "#Suppression de la ponctuation et des caractÃ¨res de l'inputdict\n",
        "def split_syll(sentences):\n",
        "  s=' '\n",
        "  phrase_clean = []\n",
        "  for sentence in sentences:\n",
        "    for word, initial in inputdict.items():\n",
        "      sentence = sentence.replace(word.lower(), initial)\n",
        "    phrase_clean.append(sentence)\n",
        "  return(phrase_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRtw0sAPQ6fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def syllabify_sentences(sentences):\n",
        "  new_sentences = []\n",
        "  for i in sentences:\n",
        "    word = f.syllabify(i)\n",
        "    word = split_syll(word)\n",
        "    i = epi.transliterate(word[0])\n",
        "    new_sentences.append(i)\n",
        "  return(new_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q7UgaXJzY9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "syll_sequences = syllabify_sentences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFYqzLfAR2qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPA_phonemes = [['É','a'],['e', 'É', 'ÉË', 'É'],['i', 'j'],['o','É'],['wa','wÉ','wÉÌ'],['u','w'],['y','É¥']\n",
        "              ,['Ã¸','Å','e'],['ÉÌ'], ['ÉÌ'], ['ÉÌ','in','ÅÌ'], ['b'], ['ks','k','kw'],['sj','si']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdpTO6mh21NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for oral in IPA_char:\n",
        "  IPA_phonemes.append([oral])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pav8OJAXCH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oral_vowel = ['i','e','É','y','Ã¸','É','Å','u','o','É','É','a']\n",
        "oral_cons = ['b','k','s','g','Ê','d','f','Ê','É¡w','l','p','t','v','z','Ê',]\n",
        "nas_cons = ['m','n','É²','Å']\n",
        "nas_vowel = ['ÉÌ','ÅÌ','ÉÌ','ÉÌ']\n",
        "semi_cons = ['j','w','É¥']\n",
        "IPA_char = oral_vowel+oral_cons+nas_cons+nas_vowel+semi_cons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKPrc_Aol4Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matrixer(sequence):\n",
        "  #Use IPA from the 1st sequence in sequences_list\n",
        "  vowels = IPA_phonemes\n",
        "  vector = list()\n",
        "#  sequence = sequence.lower()\n",
        "  for vowel in vowels:\n",
        "    somme = 0\n",
        "    for v in vowel:\n",
        "      somme+=sequence.count(v)\n",
        "    vector.append(somme)\n",
        "#  seq = ''.join([l for l in sequence if l in vowels])\n",
        "#  for vowel in vowels:\n",
        "#    for v in vowel:\n",
        "#      if seq[-1] in v:\n",
        "#        vector.append(1)\n",
        "#      else:\n",
        "#        vector.append(0)\n",
        "  return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU8oUSQKyy64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dotproduct(v1, v2):\n",
        "  return sum((a*b) for a, b in zip(v1, v2))\n",
        "\n",
        "def length(v):\n",
        "  return math.sqrt(dotproduct(v, v))\n",
        "\n",
        "def angle(v1, v2):\n",
        "  return math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxT5QEdey-L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare(list_of_sequences):\n",
        "  print('- {}'.format(list_of_sequences[0]))\n",
        "  sequences=[]\n",
        "  for i in list_of_sequences:\n",
        "    sequences.append(syllabify_sentences(i))\n",
        "  vectors = list()\n",
        "  angles = list()\n",
        "  \n",
        "  for seq in sequences:\n",
        "    vectors.append(matrixer(seq))\n",
        "  \n",
        "  for i in range(1,len(list_of_sequences)):\n",
        "    angles.append(angle(vectors[0],vectors[i]))\n",
        "#    print(\"Phrase:{} | Angle:{}\".format(list_of_sequences[i],round(angle(vectors[0],vectors[i]),2)))\n",
        "\n",
        "  return(\"Best rime: {}\".format(list_of_sequences[angles.index(min(angles))+1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtIEd-IAGrt",
        "colab_type": "code",
        "outputId": "e54e1f54-b93b-42a6-a89d-3c307787a569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for sequence in sequences:\n",
        "  print(sequence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vitamine verte pÃ©dÃ© des fois jmimagine espÃ©rer\n",
            "vis ta vie jette les dÃ©s mÃªme si les pyramides guettent pÃ©dÃ©\n",
            "la vie ma fait connaÃ®tre des putains dâbraves avec des tÃªtes de lossbar\n",
            "mais ces lascars qui font du zgar et mont lance-ba mÃ©ritent loscar\n",
            "seuls les coups durs officialisent les reufs\n",
            "quand tes dans le vice la vie cest reuch\n",
            "il faut quje fasse le point je nsuis pas devin mais si je clamse demain\n",
            "jveux pas qulimpact dune balle de flingue devienne mon clap de fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUeRIYaA3q-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unique(liste):\n",
        "    # intilize a null list\n",
        "    unique_list = []\n",
        "    # traverse for all elements\n",
        "    for x in liste:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return(unique_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-qowkRMDFZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPA_syll = unique(syll_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iYgE6bY9isL",
        "colab_type": "code",
        "outputId": "086728f7-c19f-44b6-dbd8-7cdaa18f08b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "compare(sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- vitamine verte pÃ©dÃ© des fois jmimagine espÃ©rer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Best rime: vis ta vie jette les dÃ©s mÃªme si les pyramides guettent pÃ©dÃ©'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPGlNq8C5oJb",
        "colab_type": "code",
        "outputId": "7960c1cb-91a2-4cac-f782-3ad6710d866d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(\"{}\".format(IPA_syll))\n",
        "print(\"{}\".format(matrixer(sequence)))\n",
        "print(\"{}\".format(matrixer(sequence1)))\n",
        "print(\"{}\".format(matrixer(sequence3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['t', 'É', 'y', ' ', 'p', 'r', 'É', 's', 'd', 'i', 'k', 'n', 'Ê', 'v', 'a', 'm', 'É']\n",
            "[4, 9, 5, 1, 0, 4, 0, 9, 0, 0, 2, 1, 0, 0, 4, 9, 0, 0, 0, 0, 0, 4, 1, 0, 0, 4, 3, 1, 1, 4, 2, 2, 0, 1, 1, 0, 0, 0, 0, 5, 2, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[2, 9, 5, 0, 0, 1, 1, 9, 0, 0, 0, 0, 0, 1, 4, 9, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 6, 3, 0, 2, 0, 1, 6, 0, 0, 0, 0, 2, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[7, 4, 3, 3, 0, 2, 0, 4, 0, 0, 0, 1, 0, 0, 3, 4, 0, 0, 0, 0, 0, 2, 3, 0, 0, 7, 0, 1, 5, 1, 1, 0, 0, 1, 5, 1, 0, 0, 0, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxT3XnyhKiDt",
        "colab_type": "code",
        "outputId": "aa9b1088-8858-4355-87c3-25aa52487e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "sequences = pd.read_csv(\"damso_clean.csv\")\n",
        "seq = list(sequences.sentences)\n",
        "random.shuffle(seq)\n",
        "print(unique(syllabify_sentences(seq[0])))\n",
        "IPA_syll = unique(syllabify_sentences(seq[0]))\n",
        "compare(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ê', 't', 'É', ' ', 'f', 'r', 'a', 'i', 'p', 'l', 'y', 's', 'd', 'k', 'É', 'm', 'n', 'v', 'e']\n",
            "- jte ferai plus dcompliments jvois qutu casses dÃ©jÃ  les couilles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Best rime: jfais une croix dessus comme pilate avec jÃ©sus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNksrfjkOjXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}