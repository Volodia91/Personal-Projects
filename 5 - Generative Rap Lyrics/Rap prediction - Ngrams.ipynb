{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PNLgram (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_htt4lgHpiF",
        "colab_type": "code",
        "outputId": "5174b4f9-7aa5-4cfc-814c-cf734ede9610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "!pip install dill\n",
        "!pip install nltk==3.4\n",
        "!pip install epitran"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n",
            "Collecting nltk==3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4) (1.12.0)\n",
            "Collecting singledispatch\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4-cp36-none-any.whl size=1436384 sha256=116b395a80868f4a11e4d905a62f9660ca474676559b6f1bca9bd54203d5921b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
            "Successfully built nltk\n",
            "Installing collected packages: singledispatch, nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4 singledispatch-3.4.0.3\n",
            "Collecting epitran\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/ce/ebf70bb24f220c628d4ce1e153c07e95f59132a1d882b586427ade2b1b3d/epitran-1.8-py2.py3-none-any.whl (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.6MB/s \n",
            "\u001b[?25hCollecting unicodecsv\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 7.5MB/s \n",
            "\u001b[?25hCollecting panphon>=0.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/25/935f443f0a2cce5d7a4b6b0d9101c990a6f3c74702c02287d4addd3fe009/panphon-0.17-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from epitran) (46.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from epitran) (2019.12.20)\n",
            "Collecting munkres\n",
            "  Downloading https://files.pythonhosted.org/packages/64/97/61ddc63578870e04db6eb1d3bee58ad4e727f682068a7c7405edb8b2cdeb/munkres-1.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (1.18.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (0.5.3)\n",
            "Building wheels for collected packages: unicodecsv, marisa-trie\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp36-none-any.whl size=10768 sha256=c06766a5d366f125082c415b25417ad89805663b114701d4b96f904fcefa8d11\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862307 sha256=bb5ff0d3978bac021d669663a29bf55133e257355c0814a0426761e3e87b005a\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built unicodecsv marisa-trie\n",
            "Installing collected packages: unicodecsv, marisa-trie, munkres, panphon, epitran\n",
            "Successfully installed epitran-1.8 marisa-trie-0.7.5 munkres-1.1.2 panphon-0.17 unicodecsv-0.14.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwCyroenyltG",
        "colab_type": "code",
        "outputId": "b765872c-6582-4cec-9405-9459fe0bb76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk import word_tokenize, sent_tokenize \n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "from nltk.lm import Laplace\n",
        "\n",
        "import epitran\n",
        "\n",
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import random\n",
        "from bisect import bisect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-dhrWZyr7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "booba = pd.read_csv(\"booba.csv\",index_col=0)\n",
        "damso = pd.read_csv(\"damso.csv\",index_col=0)\n",
        "guizmo = pd.read_csv(\"guizmo.csv\",index_col=0)\n",
        "kaaris = pd.read_csv(\"kaaris.csv\",index_col=0)\n",
        "lomepal = pd.read_csv(\"lomepal.csv\",index_col=0)\n",
        "nekfeu = pd.read_csv(\"nekfeu.csv\",index_col=0)\n",
        "nepal = pd.read_csv(\"nepal_clean.csv\")\n",
        "orelsan = pd.read_csv(\"orelsan.csv\",index_col=0)\n",
        "pnl = pd.read_csv(\"pnl.csv\",index_col=0)\n",
        "sch = pd.read_csv(\"sch.csv\",index_col=0)\n",
        "vald = pd.read_csv(\"vald.csv\",index_col=0)\n",
        "jul = pd.read_csv(\"jul.csv\", index_col=0)\n",
        "\n",
        "\n",
        "df = nepal\n",
        "#jul.reset_index(drop=True)\n",
        "#booba.append(damso).append(guizmo).append(kaaris).append(lomepal).append(nekfeu).append(nepal).append(orelsan).append(pnl).append(sch).append(vald).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSB0IOvraSbH",
        "colab_type": "code",
        "outputId": "9b05b95a-bac1-483f-ddec-63d4d4830a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tous mes gavanavas sont pravêts à scuiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>décoctions en mélangeant cool-al et nectar fruité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jai des taches sur mon jogging les autres sont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jme suis mis une vélocirapta gros jétais pas prêt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jarrive sur ton davos comme une pluie acide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences\n",
              "0          tous mes gavanavas sont pravêts à scuiter\n",
              "1  décoctions en mélangeant cool-al et nectar fruité\n",
              "2  jai des taches sur mon jogging les autres sont...\n",
              "3  jme suis mis une vélocirapta gros jétais pas prêt\n",
              "4        jarrive sur ton davos comme une pluie acide"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hz_ZcdXalvg",
        "colab_type": "code",
        "outputId": "923cf8dd-c709-4076-f44b-fdf8569763e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vald.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>lyrics_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3 heures de députés des pu</td>\n",
              "      <td>Des putes et des putes (x5684)</td>\n",
              "      <td>des putes et des putes  x5684 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3 heures de surprise</td>\n",
              "      <td>Suce ma bite, suce ma bite, suce ma bite, suce...</td>\n",
              "      <td>suce ma bite  suce ma bite  suce ma bite  suce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Acacia</td>\n",
              "      <td>Vitamine verte, pédé, des fois j'm'imagine esp...</td>\n",
              "      <td>vitamine verte  pédé  des fois j m imagine esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Accordé</td>\n",
              "      <td>Ah ouais, ouais, ouais, ouais, ouais, ouais, o...</td>\n",
              "      <td>ah ouais  ouais  ouais  ouais  ouais  ouais  o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Acte de foi</td>\n",
              "      <td>On ne prône pas la violence, le matos le fait\\...</td>\n",
              "      <td>on ne prône pas la violence  le matos le fait\\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        title  ...                                       lyrics_clean\n",
              "0  3 heures de députés des pu  ...         des putes et des putes  x5684 \\n          \n",
              "1        3 heures de surprise  ...  suce ma bite  suce ma bite  suce ma bite  suce...\n",
              "2                      Acacia  ...  vitamine verte  pédé  des fois j m imagine esp...\n",
              "3                     Accordé  ...  ah ouais  ouais  ouais  ouais  ouais  ouais  o...\n",
              "4                 Acte de foi  ...  on ne prône pas la violence  le matos le fait\\...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvMyxE4q3XBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initmodel(n=4,df=df):\n",
        "  splilist=[]\n",
        "  for lyr in df.sentences:\n",
        "    lyr.replace(\"’\",\" \")\n",
        "    lyr.replace(\"“\",\" \")\n",
        "    lyr = lyr.split()\n",
        "    lyr.insert(0,\"<s>\")\n",
        "    lyr.append(\"</s>\")\n",
        "    splilist.append(lyr)\n",
        "\n",
        "  train_data_clean = (everygrams(sent, 1, n) for sent in splilist)\n",
        "  sents = flatten(splilist)\n",
        "\n",
        "  model = Laplace(n)\n",
        "  model.fit(train_data_clean, sents)\n",
        "  return model\n",
        "\n",
        "def _random_generator(seed_or_generator):\n",
        "    if isinstance(seed_or_generator, random.Random):\n",
        "        return seed_or_generator\n",
        "    return random.Random(seed_or_generator)\n",
        "\n",
        "def _weighted_choice(population, weights, random_generator=None):\n",
        "    if not population:\n",
        "        raise ValueError(\"Can't choose from empty population\")\n",
        "    if len(population) != len(weights):\n",
        "        raise ValueError(\"The number of weights does not match the population\")\n",
        "    cum_weights = list(itertools.accumulate(weights))\n",
        "    total = cum_weights[-1]\n",
        "    threshold = random_generator.random()\n",
        "    return population[bisect(cum_weights, total * threshold)]\n",
        "\n",
        "def generate(model, num_words=1, text_seed=None, random_seed=None):\n",
        "        text_seed = [] if text_seed is None else list(text_seed)\n",
        "        random_generator = _random_generator(random_seed)\n",
        "        if num_words == 1:\n",
        "            context = (\n",
        "                text_seed[-model.order + 1 :]\n",
        "                if len(text_seed) >= model.order\n",
        "                else text_seed\n",
        "            )\n",
        "            samples = model.context_counts(model.vocab.lookup(context))\n",
        "            while context and not samples:\n",
        "                context = context[1:] if len(context) > 1 else []\n",
        "                samples = model.context_counts(model.vocab.lookup(context))\n",
        "            samples = sorted(samples)\n",
        "            return _weighted_choice(samples, tuple(model.score(w, context) for w in samples), random_generator), samples\n",
        "        generated = []\n",
        "        for _ in range(num_words):\n",
        "            genword, samples = generate(model=model,num_words=1,text_seed=text_seed + generated,random_seed=random_generator)\n",
        "            try:\n",
        "              while genword == generated[-1] and genword == generated[-2]:\n",
        "                genword = random.choice(list(model.vocab))\n",
        "            except IndexError:\n",
        "                pass\n",
        "            generated.append(genword)\n",
        "        return generated\n",
        "\n",
        "def generate_sent(model, num_words, text_seed=None, random_seed=None):\n",
        "    if text_seed is not None:\n",
        "      content = [text_seed]\n",
        "    else:\n",
        "      content = []\n",
        "    for token in generate(model=model, num_words=num_words, text_seed=text_seed, random_seed=random_seed):\n",
        "      if token == \"</s>\":\n",
        "        break\n",
        "      content.append(token)\n",
        "    return \" \".join(content)\n",
        "\n",
        "def dotproduct(v1, v2):\n",
        "  return sum((a*b) for a, b in zip(v1, v2))\n",
        "\n",
        "def length(v):\n",
        "  return math.sqrt(dotproduct(v, v))\n",
        "\n",
        "def angle(v1, v2):\n",
        "  return math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
        "\n",
        "def matrixer(sequence):\n",
        "  vowels = [\"j\",\"w\",\"ɥ\",\"a\",\"ɑ\",\"e\",\"ɛ\",\"ɛː\",\"ə\",\"i\",\"œ\",\"ø\",\"o\",\"ɔ\",\"u\",\"y\",\"ɑ̃\",\"ɛ̃\",\"œ̃\",\"ɔ̃\"]\n",
        "  vector = list()\n",
        "\n",
        "  epi = epitran.Epitran('fra-Latn')\n",
        "\n",
        "  sequence = sequence.lower()\n",
        "  sequence = epi.transliterate(sequence)\n",
        "\n",
        "  for vowel in vowels:\n",
        "    vector.append(sequence.count(vowel))\n",
        "\n",
        "  seq = ''.join([l for l in sequence if l in vowels])\n",
        "  for vowel in vowels:\n",
        "    if seq[-1] == vowel:\n",
        "      vector.append(1)\n",
        "    else:\n",
        "      vector.append(0)\n",
        "  return vector\n",
        "\n",
        "def compare(context,sequences):\n",
        "  sequences.insert(0,context)\n",
        "  vectors = list()\n",
        "  angles = list()\n",
        "  \n",
        "  for seq in sequences:\n",
        "    vectors.append(matrixer(seq))\n",
        "  \n",
        "  for i in range(len(vectors)-1):\n",
        "    angles.append(angle(vectors[0],vectors[i+1]))\n",
        "\n",
        "  return sequences[angles.index(min(angles))+1]\n",
        "\n",
        "def save_model(model,name=\"model.pickle\"):\n",
        "  f = open(name, 'wb')\n",
        "  pickle.dump(model, f)\n",
        "  f.close()\n",
        "\n",
        "def load_model(model,name=\"model.pickle\"):\n",
        "  f = open(name, 'rb')\n",
        "  model = pickle.load(f)\n",
        "  f.close()\n",
        "  return model\n",
        "\n",
        "def couplet(model=initmodel(),sents=5,comp=5):\n",
        "  sentlist = [generate_sent(model,np.random.randint(5,21))]\n",
        "  for i in range(sents):\n",
        "    context = sentlist[-1]\n",
        "    trials=list()\n",
        "    for j in range(comp):\n",
        "      trials.append(generate_sent(model,np.random.randint(5,21)))\n",
        "      print(\"Trial\",j,\"done\")\n",
        "    sentlist.append(compare(context, trials))\n",
        "    print(\"Sentence\",i,\"done\")\n",
        "  return \"\\n\".join(sentlist)\n",
        "\n",
        "def refrain(model=initmodel(), comp=5, form=None):\n",
        "  sentlist = [\" \".join(model.generate(np.random.randint(5,15)))]\n",
        "  context = sentlist[0]\n",
        "  trials = list()\n",
        "  for j in range(comp):\n",
        "    trials.append(\" \".join(model.generate(np.random.randint(5,15))))\n",
        "  sentlist.append(compare(context,trials))\n",
        "  if form == None:\n",
        "    form = np.random.randint(0,3)\n",
        "  if form == 0:\n",
        "    return \"\\n\".join([sentlist[0],sentlist[1],sentlist[0],sentlist[1]])\n",
        "  elif form == 1:\n",
        "    return \"\\n\".join([sentlist[0],sentlist[0],sentlist[1],sentlist[1]])\n",
        "  elif form == 2:\n",
        "    return \"\\n\".join([sentlist[0],sentlist[1],sentlist[1],sentlist[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ng2QnNeDfZZ",
        "colab": {}
      },
      "source": [
        "print(couplet(initmodel(3,pnl)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6gP_Jlp-_cv",
        "colab_type": "code",
        "outputId": "0866c68d-db20-4454-d9ce-abf540b76a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(refrain(initmodel(3,nepal)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "des séries dsquats quest-ce que\n",
            "des séries dsquats quest-ce que\n",
            "àl faute de time </s> dun vieux président mort en 50 exemplaires\n",
            "àl faute de time </s> dun vieux président mort en 50 exemplaires\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_obMTe9p5fEN",
        "colab_type": "code",
        "outputId": "35c9d1a7-fa04-4077-d347-6c30a96a5c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "print(couplet(initmodel(1,nepal)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 0 done\n",
            "Trial 1 done\n",
            "Trial 2 done\n",
            "Trial 3 done\n",
            "Trial 4 done\n",
            "Sentence 0 done\n",
            "Trial 0 done\n",
            "Trial 1 done\n",
            "Trial 2 done\n",
            "Trial 3 done\n",
            "Trial 4 done\n",
            "Sentence 1 done\n",
            "Trial 0 done\n",
            "Trial 1 done\n",
            "Trial 2 done\n",
            "Trial 3 done\n",
            "Trial 4 done\n",
            "Sentence 2 done\n",
            "Trial 0 done\n",
            "Trial 1 done\n",
            "Trial 2 done\n",
            "Trial 3 done\n",
            "Trial 4 done\n",
            "Sentence 3 done\n",
            "Trial 0 done\n",
            "Trial 1 done\n",
            "Trial 2 done\n",
            "Trial 3 done\n",
            "Trial 4 done\n",
            "Sentence 4 done\n",
            "j mh qui en les cuiter penchants dièses si\n",
            "me plus faire à à san quelqu bateaux ulcères gros il\n",
            "t comme j track un hey la lisa magnifique\n",
            "cause monde la ra on la que mon going le depuis terrible\n",
            "gorge refaire bave cristallise toaster t ça 2 alentours l spécial\n",
            "je même l sugar ça pour pondre quitter croyable remplir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdrULQZ3otS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}